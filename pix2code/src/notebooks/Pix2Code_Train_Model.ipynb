{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938af90f-a81b-4269-a955-bb3dbe4ba829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "\n",
    "platform_list = [\"android\", \"ios\",\"web\"]\n",
    "\n",
    "\n",
    "BASE_DIR = \"/Users/abhjha8/Image2Code/pix2code/src/dataset/{0}/all_data\"\n",
    "TRAINING_SET_NAME = \"training_set\"\n",
    "EVALUATION_SET_NAME = \"eval_set\"\n",
    "distribution = 6 # to decide the ratio of training and evaluation samples size\n",
    "\n",
    "\n",
    "input_path_list = []\n",
    "\n",
    "for platform in platform_list:\n",
    "    input_path = BASE_DIR.format(platform)\n",
    "    input_path_list.append(input_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33166365-41d9-4833-b00e-3e37dcf18469",
   "metadata": {},
   "source": [
    "# PREPARE THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def0200e-c54e-4769-b532-9d1e57b8cf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting datasets, training samples: 1500.0, evaluation samples: 250.0\n",
      "Training dataset: /Users/abhjha8/Image2Code/pix2code/src/dataset/android/training_set\n",
      "Evaluation dataset: /Users/abhjha8/Image2Code/pix2code/src/dataset/android/eval_set\n",
      "Splitting datasets, training samples: 1500.0, evaluation samples: 250.0\n",
      "Training dataset: /Users/abhjha8/Image2Code/pix2code/src/dataset/ios/training_set\n",
      "Evaluation dataset: /Users/abhjha8/Image2Code/pix2code/src/dataset/ios/eval_set\n",
      "Splitting datasets, training samples: 1500.0, evaluation samples: 250.0\n",
      "Training dataset: /Users/abhjha8/Image2Code/pix2code/src/dataset/web/training_set\n",
      "Evaluation dataset: /Users/abhjha8/Image2Code/pix2code/src/dataset/web/eval_set\n"
     ]
    }
   ],
   "source": [
    "for input_path in input_path_list:\n",
    "    paths = []\n",
    "\n",
    "    for f in os.listdir(input_path):\n",
    "        if f.find(\".gui\") != -1:\n",
    "            path_gui = \"{}/{}\".format(input_path, f)\n",
    "            file_name = f[:f.find(\".gui\")]\n",
    "\n",
    "            if os.path.isfile(\"{}/{}.png\".format(input_path, file_name)):\n",
    "                path_img = \"{}/{}.png\".format(input_path, file_name)\n",
    "                paths.append(file_name)\n",
    "\n",
    "    evaluation_samples_number = len(paths) / (distribution + 1)\n",
    "    training_samples_number = evaluation_samples_number * distribution\n",
    "\n",
    "    assert training_samples_number + evaluation_samples_number == len(paths)\n",
    "\n",
    "    print(\"Splitting datasets, training samples: {}, evaluation samples: {}\".format(training_samples_number, evaluation_samples_number))\n",
    "\n",
    "    np.random.shuffle(paths)\n",
    "\n",
    "    eval_set = []\n",
    "    train_set = []\n",
    "    hashes = []\n",
    "    for path in paths:\n",
    "        with open(\"{}/{}.gui\".format(input_path, path), 'r', encoding='utf-8') as f:\n",
    "            chars = \"\"\n",
    "            for line in f:\n",
    "                chars += line\n",
    "            content_hash = chars.replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "            content_hash = hashlib.sha256(content_hash.encode('utf-8')).hexdigest()\n",
    "\n",
    "            if len(eval_set) == evaluation_samples_number:\n",
    "                train_set.append(path)\n",
    "            else:\n",
    "                is_unique = True\n",
    "                for h in hashes:\n",
    "                    if h is content_hash:\n",
    "                        is_unique = False\n",
    "                        break\n",
    "\n",
    "                if is_unique:\n",
    "                    eval_set.append(path)\n",
    "                else:\n",
    "                    train_set.append(path)\n",
    "\n",
    "            hashes.append(content_hash)\n",
    "\n",
    "    assert len(eval_set) == evaluation_samples_number\n",
    "    assert len(train_set) == training_samples_number\n",
    "\n",
    "    if not os.path.exists(\"{}/{}\".format(os.path.dirname(input_path), EVALUATION_SET_NAME)):\n",
    "        os.makedirs(\"{}/{}\".format(os.path.dirname(input_path), EVALUATION_SET_NAME))\n",
    "\n",
    "    if not os.path.exists(\"{}/{}\".format(os.path.dirname(input_path), TRAINING_SET_NAME)):\n",
    "        os.makedirs(\"{}/{}\".format(os.path.dirname(input_path), TRAINING_SET_NAME))\n",
    "\n",
    "    for path in eval_set:\n",
    "        shutil.copyfile(\"{}/{}.png\".format(input_path, path), \"{}/{}/{}.png\".format(os.path.dirname(input_path), EVALUATION_SET_NAME, path))\n",
    "        shutil.copyfile(\"{}/{}.gui\".format(input_path, path), \"{}/{}/{}.gui\".format(os.path.dirname(input_path), EVALUATION_SET_NAME, path))\n",
    "\n",
    "    for path in train_set:\n",
    "        shutil.copyfile(\"{}/{}.png\".format(input_path, path), \"{}/{}/{}.png\".format(os.path.dirname(input_path), TRAINING_SET_NAME, path))\n",
    "        shutil.copyfile(\"{}/{}.gui\".format(input_path, path), \"{}/{}/{}.gui\".format(os.path.dirname(input_path), TRAINING_SET_NAME, path))\n",
    "\n",
    "    print(\"Training dataset: {}/training_set\".format(os.path.dirname(input_path), path))\n",
    "    print(\"Evaluation dataset: {}/eval_set\".format(os.path.dirname(input_path), path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f047b6-4607-470d-b280-467bafea4015",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting images to numpy arrays...\n",
      "Numpy arrays saved in /Users/abhjha8/Image2Code/pix2code/src/dataset/android/training_features\n",
      "Numpy arrays saved in /Users/abhjha8/Image2Code/pix2code/src/dataset/ios/training_features\n",
      "Numpy arrays saved in /Users/abhjha8/Image2Code/pix2code/src/dataset/web/training_features\n"
     ]
    }
   ],
   "source": [
    "def get_preprocessed_img(img_path, image_size):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (image_size, image_size))\n",
    "    img = img.astype('float32')\n",
    "    img /= 255\n",
    "    return img\n",
    "\n",
    "\n",
    "TRAIN_IMAGE_DIR = \"/Users/abhjha8/Image2Code/pix2code/src/dataset/{0}/training_set\"\n",
    "TRAIN_FEATURES_DIR = \"/Users/abhjha8/Image2Code/pix2code/src/dataset/{0}/training_features\"\n",
    "input_path_list = []\n",
    "output_path_mapping = dict()\n",
    "for platform in platform_list:\n",
    "    input_path = TRAIN_IMAGE_DIR.format(platform)\n",
    "    output_path_mapping[input_path] = TRAIN_FEATURES_DIR.format(platform)\n",
    "    if not os.path.exists(output_path_mapping[input_path]):\n",
    "        os.makedirs(output_path_mapping[input_path])\n",
    "    input_path_list.append(input_path)\n",
    "\n",
    "\n",
    "print(\"Converting images to numpy arrays...\")\n",
    "for input_path in input_path_list:\n",
    "    output_path = output_path_mapping[input_path]\n",
    "    for f in os.listdir(input_path):\n",
    "        if f.find(\".png\") != -1:\n",
    "            img = get_preprocessed_img(\"{}/{}\".format(input_path, f), IMAGE_SIZE)\n",
    "            file_name = f[:f.find(\".png\")]\n",
    "\n",
    "            np.savez_compressed(\"{}/{}\".format(output_path, file_name), features=img)\n",
    "            retrieve = np.load(\"{}/{}.npz\".format(output_path, file_name))[\"features\"]\n",
    "\n",
    "            assert np.array_equal(img, retrieve)\n",
    "\n",
    "            shutil.copyfile(\"{}/{}.gui\".format(input_path, file_name), \"{}/{}.gui\".format(output_path, file_name))\n",
    "\n",
    "    print(\"Numpy arrays saved in {}\".format(output_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb7012a-b0f8-4854-9696-2b4760453fd6",
   "metadata": {},
   "source": [
    "# Training the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a16e54cf-8bfe-49e1-86d5-1da7a352db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "class AModel:\n",
    "    def __init__(self, input_shape, output_size, output_path):\n",
    "        self.model = None\n",
    "        self.input_shape = input_shape\n",
    "        self.output_size = output_size\n",
    "        self.output_path = output_path\n",
    "        self.name = \"\"\n",
    "\n",
    "    def save(self):\n",
    "        model_json = self.model.to_json()\n",
    "        with open(\"{}/{}.json\".format(self.output_path, self.name), \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        self.model.save_weights(\"{}/{}.h5\".format(self.output_path, self.name))\n",
    "\n",
    "    def load(self, name=\"\"):\n",
    "        output_name = self.name if name == \"\" else name\n",
    "        with open(\"{}/{}.json\".format(self.output_path, output_name), \"r\") as json_file:\n",
    "            loaded_model_json = json_file.read()\n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        self.model.load_weights(\"{}/{}.h5\".format(self.output_path, output_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314de257-e2f8-41da-92b0-2e4b1dcefda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Input, Dense, Dropout, \\\n",
    "                         RepeatVector, LSTM, concatenate, \\\n",
    "                         Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers.legacy import RMSprop\n",
    "from keras import *\n",
    "\n",
    "class pix2code(AModel):\n",
    "    def __init__(self, input_shape, output_size, output_path):\n",
    "        AModel.__init__(self, input_shape, output_size, output_path)\n",
    "        self.name = \"pix2code\"\n",
    "\n",
    "        image_model = Sequential()\n",
    "        image_model.add(Conv2D(32, (3, 3), padding='valid', activation='relu', input_shape=input_shape))\n",
    "        image_model.add(Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "        image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        image_model.add(Dropout(0.25))\n",
    "\n",
    "        image_model.add(Conv2D(64, (3, 3), padding='valid', activation='relu'))\n",
    "        image_model.add(Conv2D(64, (3, 3), padding='valid', activation='relu'))\n",
    "        image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        image_model.add(Dropout(0.25))\n",
    "\n",
    "        image_model.add(Conv2D(128, (3, 3), padding='valid', activation='relu'))\n",
    "        image_model.add(Conv2D(128, (3, 3), padding='valid', activation='relu'))\n",
    "        image_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        image_model.add(Dropout(0.25))\n",
    "\n",
    "        image_model.add(Flatten())\n",
    "        image_model.add(Dense(1024, activation='relu'))\n",
    "        image_model.add(Dropout(0.3))\n",
    "        image_model.add(Dense(1024, activation='relu'))\n",
    "        image_model.add(Dropout(0.3))\n",
    "\n",
    "        image_model.add(RepeatVector(CONTEXT_LENGTH))\n",
    "\n",
    "        visual_input = Input(shape=input_shape)\n",
    "        encoded_image = image_model(visual_input)\n",
    "\n",
    "        language_model = Sequential()\n",
    "        language_model.add(LSTM(128, return_sequences=True, input_shape=(CONTEXT_LENGTH, output_size)))\n",
    "        language_model.add(LSTM(128, return_sequences=True))\n",
    "\n",
    "        textual_input = Input(shape=(CONTEXT_LENGTH, output_size))\n",
    "        encoded_text = language_model(textual_input)\n",
    "\n",
    "        decoder = concatenate([encoded_image, encoded_text])\n",
    "\n",
    "        decoder = LSTM(512, return_sequences=True)(decoder)\n",
    "        decoder = LSTM(512, return_sequences=False)(decoder)\n",
    "        decoder = Dense(output_size, activation='softmax')(decoder)\n",
    "\n",
    "        self.model = Model(inputs=[visual_input, textual_input], outputs=decoder)\n",
    "\n",
    "        optimizer = RMSprop(learning_rate=0.0001, clipvalue=1.0)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def fit(self, images, partial_captions, next_words):\n",
    "        self.model.fit([images, partial_captions], next_words, shuffle=False, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "        self.save()\n",
    "\n",
    "    def fit_generator(self, generator, steps_per_epoch):\n",
    "        self.model.fit(generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, verbose=1)\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, image, partial_caption):\n",
    "        return self.model.predict([image, partial_caption], verbose=0)[0]\n",
    "\n",
    "    def predict_batch(self, images, partial_captions):\n",
    "        return self.model.predict([images, partial_captions], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e24c75-92d8-4739-b377-e3eb67c4eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = 48\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "STEPS_PER_EPOCH = 72000\n",
    "\n",
    "\n",
    "START_TOKEN = \"<START>\"\n",
    "END_TOKEN = \"<END>\"\n",
    "PLACEHOLDER = \" \"\n",
    "SEPARATOR = '->'\n",
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.binary_vocabulary = {}\n",
    "        self.vocabulary = {}\n",
    "        self.token_lookup = {}\n",
    "        self.size = 0\n",
    "\n",
    "        self.append(START_TOKEN)\n",
    "        self.append(END_TOKEN)\n",
    "        self.append(PLACEHOLDER)\n",
    "\n",
    "    def append(self, token):\n",
    "        if token not in self.vocabulary:\n",
    "            self.vocabulary[token] = self.size\n",
    "            self.token_lookup[self.size] = token\n",
    "            self.size += 1\n",
    "\n",
    "    def create_binary_representation(self):\n",
    "        if sys.version_info >= (3,):\n",
    "            items = self.vocabulary.items()\n",
    "        else:\n",
    "            items = self.vocabulary.iteritems()\n",
    "        for key, value in items:\n",
    "            binary = np.zeros(self.size)\n",
    "            binary[value] = 1\n",
    "            self.binary_vocabulary[key] = binary\n",
    "\n",
    "    def get_serialized_binary_representation(self):\n",
    "        if len(self.binary_vocabulary) == 0:\n",
    "            self.create_binary_representation()\n",
    "\n",
    "        string = \"\"\n",
    "        if sys.version_info >= (3,):\n",
    "            items = self.binary_vocabulary.items()\n",
    "        else:\n",
    "            items = self.binary_vocabulary.iteritems()\n",
    "        for key, value in items:\n",
    "            array_as_string = np.array2string(value, separator=',', max_line_width=self.size * self.size)\n",
    "            string += \"{}{}{}\\n\".format(key, SEPARATOR, array_as_string[1:len(array_as_string) - 1])\n",
    "        return string\n",
    "\n",
    "    def save(self, path):\n",
    "        output_file_name = \"{}/words.vocab\".format(path)\n",
    "        output_file = open(output_file_name, 'w')\n",
    "        output_file.write(self.get_serialized_binary_representation())\n",
    "        output_file.close()\n",
    "        print(\"Saved vocabulary file\")\n",
    "\n",
    "    def retrieve(self, path):\n",
    "        input_file = open(\"{}/words.vocab\".format(path), 'r')\n",
    "        buffer = \"\"\n",
    "        for line in input_file:\n",
    "            try:\n",
    "                separator_position = len(buffer) + line.index(SEPARATOR)\n",
    "                buffer += line\n",
    "                key = buffer[:separator_position]\n",
    "                value = buffer[separator_position + len(SEPARATOR):]\n",
    "                value = np.fromstring(value, sep=',')\n",
    "\n",
    "                self.binary_vocabulary[key] = value\n",
    "                self.vocabulary[key] = np.where(value == 1)[0][0]\n",
    "                self.token_lookup[np.where(value == 1)[0][0]] = key\n",
    "\n",
    "                buffer = \"\"\n",
    "            except ValueError:\n",
    "                buffer += line\n",
    "        input_file.close()\n",
    "        self.size = len(self.vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f80ebb7-3122-49b3-8d41-f09792b67f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    @staticmethod\n",
    "    def sparsify(label_vector, output_size):\n",
    "        sparse_vector = []\n",
    "\n",
    "        for label in label_vector:\n",
    "            sparse_label = np.zeros(output_size)\n",
    "            sparse_label[label] = 1\n",
    "\n",
    "            sparse_vector.append(sparse_label)\n",
    "\n",
    "        return np.array(sparse_vector)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_preprocessed_img(img_path, image_size):\n",
    "        import cv2\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        img = img.astype('float32')\n",
    "        img /= 255\n",
    "        return img\n",
    "\n",
    "    @staticmethod\n",
    "    def show(image):\n",
    "        import cv2\n",
    "        cv2.namedWindow(\"view\", cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow(\"view\", image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyWindow(\"view\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1493e97a-f379-42b2-acbc-875bdf754545",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.input_shape = None\n",
    "        self.output_size = None\n",
    "\n",
    "        self.ids = []\n",
    "        self.input_images = []\n",
    "        self.partial_sequences = []\n",
    "        self.next_words = []\n",
    "\n",
    "        self.voc = Vocabulary()\n",
    "        self.size = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def load_paths_only(path):\n",
    "        print(\"Parsing data...\")\n",
    "        gui_paths = []\n",
    "        img_paths = []\n",
    "        for f in os.listdir(path):\n",
    "            if f.find(\".gui\") != -1:\n",
    "                path_gui = \"{}/{}\".format(path, f)\n",
    "                gui_paths.append(path_gui)\n",
    "                file_name = f[:f.find(\".gui\")]\n",
    "\n",
    "                if os.path.isfile(\"{}/{}.png\".format(path, file_name)):\n",
    "                    path_img = \"{}/{}.png\".format(path, file_name)\n",
    "                    img_paths.append(path_img)\n",
    "                elif os.path.isfile(\"{}/{}.npz\".format(path, file_name)):\n",
    "                    path_img = \"{}/{}.npz\".format(path, file_name)\n",
    "                    img_paths.append(path_img)\n",
    "\n",
    "        assert len(gui_paths) == len(img_paths)\n",
    "        return gui_paths, img_paths\n",
    "\n",
    "    def load(self, path, generate_binary_sequences=False):\n",
    "        print(\"Loading data...\")\n",
    "        for f in os.listdir(path):\n",
    "            if f.find(\".gui\") != -1:\n",
    "                gui = open(\"{}/{}\".format(path, f), 'r')\n",
    "                file_name = f[:f.find(\".gui\")]\n",
    "\n",
    "                if os.path.isfile(\"{}/{}.png\".format(path, file_name)):\n",
    "                    img = Utils.get_preprocessed_img(\"{}/{}.png\".format(path, file_name), IMAGE_SIZE)\n",
    "                    self.append(file_name, gui, img)\n",
    "                elif os.path.isfile(\"{}/{}.npz\".format(path, file_name)):\n",
    "                    img = np.load(\"{}/{}.npz\".format(path, file_name))[\"features\"]\n",
    "                    self.append(file_name, gui, img)\n",
    "\n",
    "        print(\"Generating sparse vectors...\")\n",
    "        self.voc.create_binary_representation()\n",
    "        self.next_words = self.sparsify_labels(self.next_words, self.voc)\n",
    "        if generate_binary_sequences:\n",
    "            self.partial_sequences = self.binarize(self.partial_sequences, self.voc)\n",
    "        else:\n",
    "            self.partial_sequences = self.indexify(self.partial_sequences, self.voc)\n",
    "\n",
    "        self.size = len(self.ids)\n",
    "        assert self.size == len(self.input_images) == len(self.partial_sequences) == len(self.next_words)\n",
    "        assert self.voc.size == len(self.voc.vocabulary)\n",
    "\n",
    "        print(\"Dataset size: {}\".format(self.size))\n",
    "        print(\"Vocabulary size: {}\".format(self.voc.size))\n",
    "\n",
    "        self.input_shape = self.input_images[0].shape\n",
    "        self.output_size = self.voc.size\n",
    "\n",
    "        print(\"Input shape: {}\".format(self.input_shape))\n",
    "        print(\"Output size: {}\".format(self.output_size))\n",
    "\n",
    "    def convert_arrays(self):\n",
    "        print(\"Convert arrays...\")\n",
    "        self.input_images = np.array(self.input_images)\n",
    "        self.partial_sequences = np.array(self.partial_sequences)\n",
    "        self.next_words = np.array(self.next_words)\n",
    "\n",
    "    def append(self, sample_id, gui, img, to_show=False):\n",
    "        if to_show:\n",
    "            pic = img * 255\n",
    "            pic = np.array(pic, dtype=np.uint8)\n",
    "            Utils.show(pic)\n",
    "\n",
    "        token_sequence = [START_TOKEN]\n",
    "        for line in gui:\n",
    "            line = line.replace(\",\", \" ,\").replace(\"\\n\", \" \\n\")\n",
    "            tokens = line.split(\" \")\n",
    "            for token in tokens:\n",
    "                self.voc.append(token)\n",
    "                token_sequence.append(token)\n",
    "        token_sequence.append(END_TOKEN)\n",
    "\n",
    "        suffix = [PLACEHOLDER] * CONTEXT_LENGTH\n",
    "\n",
    "        a = np.concatenate([suffix, token_sequence])\n",
    "        for j in range(0, len(a) - CONTEXT_LENGTH):\n",
    "            context = a[j:j + CONTEXT_LENGTH]\n",
    "            label = a[j + CONTEXT_LENGTH]\n",
    "\n",
    "            self.ids.append(sample_id)\n",
    "            self.input_images.append(img)\n",
    "            self.partial_sequences.append(context)\n",
    "            self.next_words.append(label)\n",
    "\n",
    "    @staticmethod\n",
    "    def indexify(partial_sequences, voc):\n",
    "        temp = []\n",
    "        for sequence in partial_sequences:\n",
    "            sparse_vectors_sequence = []\n",
    "            for token in sequence:\n",
    "                sparse_vectors_sequence.append(voc.vocabulary[token])\n",
    "            temp.append(np.array(sparse_vectors_sequence))\n",
    "\n",
    "        return temp\n",
    "\n",
    "    @staticmethod\n",
    "    def binarize(partial_sequences, voc):\n",
    "        temp = []\n",
    "        for sequence in partial_sequences:\n",
    "            sparse_vectors_sequence = []\n",
    "            for token in sequence:\n",
    "                sparse_vectors_sequence.append(voc.binary_vocabulary[token])\n",
    "            temp.append(np.array(sparse_vectors_sequence))\n",
    "\n",
    "        return temp\n",
    "\n",
    "    @staticmethod\n",
    "    def sparsify_labels(next_words, voc):\n",
    "        temp = []\n",
    "        for label in next_words:\n",
    "            temp.append(voc.binary_vocabulary[label])\n",
    "\n",
    "        return temp\n",
    "\n",
    "    def save_metadata(self, path):\n",
    "        metadata_array = np.array([self.input_shape, self.output_size, self.size], dtype=object)\n",
    "        np.save(\"{}/meta_dataset\".format(path), metadata_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "156a3f6f-8356-4b8e-931e-f66adbb2968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator:\n",
    "    @staticmethod\n",
    "    def data_generator(voc, gui_paths, img_paths, batch_size, generate_binary_sequences=False, verbose=False, loop_only_one=False):\n",
    "        assert len(gui_paths) == len(img_paths)\n",
    "        voc.create_binary_representation()\n",
    "\n",
    "        while 1:\n",
    "            batch_input_images = []\n",
    "            batch_partial_sequences = []\n",
    "            batch_next_words = []\n",
    "            sample_in_batch_counter = 0\n",
    "\n",
    "            for i in range(0, len(gui_paths)):\n",
    "                if img_paths[i].find(\".png\") != -1:\n",
    "                    img = Utils.get_preprocessed_img(img_paths[i], IMAGE_SIZE)\n",
    "                else:\n",
    "                    img = np.load(img_paths[i])[\"features\"]\n",
    "                gui = open(gui_paths[i], 'r')\n",
    "\n",
    "                token_sequence = [START_TOKEN]\n",
    "                for line in gui:\n",
    "                    line = line.replace(\",\", \" ,\").replace(\"\\n\", \" \\n\")\n",
    "                    tokens = line.split(\" \")\n",
    "                    for token in tokens:\n",
    "                        voc.append(token)\n",
    "                        token_sequence.append(token)\n",
    "                token_sequence.append(END_TOKEN)\n",
    "\n",
    "                suffix = [PLACEHOLDER] * CONTEXT_LENGTH\n",
    "\n",
    "                a = np.concatenate([suffix, token_sequence])\n",
    "                for j in range(0, len(a) - CONTEXT_LENGTH):\n",
    "                    context = a[j:j + CONTEXT_LENGTH]\n",
    "                    label = a[j + CONTEXT_LENGTH]\n",
    "\n",
    "                    batch_input_images.append(img)\n",
    "                    batch_partial_sequences.append(context)\n",
    "                    batch_next_words.append(label)\n",
    "                    sample_in_batch_counter += 1\n",
    "\n",
    "                    if sample_in_batch_counter == batch_size or (loop_only_one and i == len(gui_paths) - 1):\n",
    "                        if verbose:\n",
    "                            print(\"Generating sparse vectors...\")\n",
    "                        batch_next_words = Dataset.sparsify_labels(batch_next_words, voc)\n",
    "                        if generate_binary_sequences:\n",
    "                            batch_partial_sequences = Dataset.binarize(batch_partial_sequences, voc)\n",
    "                        else:\n",
    "                            batch_partial_sequences = Dataset.indexify(batch_partial_sequences, voc)\n",
    "\n",
    "                        if verbose:\n",
    "                            print(\"Convert arrays...\")\n",
    "                        batch_input_images = np.array(batch_input_images)\n",
    "                        batch_partial_sequences = np.array(batch_partial_sequences)\n",
    "                        batch_next_words = np.array(batch_next_words)\n",
    "\n",
    "                        if verbose:\n",
    "                            print(\"Yield batch\")\n",
    "                        yield ([batch_input_images, batch_partial_sequences], batch_next_words)\n",
    "\n",
    "                        batch_input_images = []\n",
    "                        batch_partial_sequences = []\n",
    "                        batch_next_words = []\n",
    "                        sample_in_batch_counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332ab5a-3e96-4f5d-8016-02828857bf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Generating sparse vectors...\n",
      "Dataset size: 167958\n",
      "Vocabulary size: 19\n",
      "Input shape: (256, 256, 3)\n",
      "Output size: 19\n",
      "Saved vocabulary file\n",
      "Parsing data...\n",
      "Epoch 1/10\n",
      "   3/2624 [..............................] - ETA: 2:15:47 - loss: 2.6281"
     ]
    }
   ],
   "source": [
    "random_seed_val = 1234\n",
    "def run(input_path, output_path, is_memory_intensive=True, pretrained_model=None):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    dataset = Dataset()\n",
    "    dataset.load(input_path, generate_binary_sequences=True)\n",
    "    dataset.save_metadata(output_path)\n",
    "    dataset.voc.save(output_path)\n",
    "\n",
    "    if not is_memory_intensive:\n",
    "        dataset.convert_arrays()\n",
    "\n",
    "        input_shape = dataset.input_shape\n",
    "        output_size = dataset.output_size\n",
    "\n",
    "        print(len(dataset.input_images), len(dataset.partial_sequences), len(dataset.next_words))\n",
    "        print(dataset.input_images.shape, dataset.partial_sequences.shape, dataset.next_words.shape)\n",
    "    else:\n",
    "        gui_paths, img_paths = Dataset.load_paths_only(input_path)\n",
    "\n",
    "        input_shape = dataset.input_shape\n",
    "        output_size = dataset.output_size\n",
    "        steps_per_epoch = dataset.size / BATCH_SIZE\n",
    "\n",
    "        voc = Vocabulary()\n",
    "        voc.retrieve(output_path)\n",
    "\n",
    "        generator = Generator.data_generator(voc, gui_paths, img_paths, batch_size=BATCH_SIZE, generate_binary_sequences=True)\n",
    "\n",
    "    model = pix2code(input_shape, output_size, output_path)\n",
    "\n",
    "    if pretrained_model is not None:\n",
    "        model.model.load_weights(pretrained_model)\n",
    "\n",
    "    if not is_memory_intensive:\n",
    "        model.fit(dataset.input_images, dataset.partial_sequences, dataset.next_words)\n",
    "    else:\n",
    "        model.fit_generator(generator, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(random_seed_val)\n",
    "    input_path = \"/Users/abhjha8/Image2Code/pix2code/src/dataset/web/training_set\"\n",
    "    output_path = \"/Users/abhjha8/Image2Code/pix2code/src/models/model_web\"\n",
    "    use_generator = True\n",
    "    pretrained_weigths = None\n",
    "    run(input_path, output_path, is_memory_intensive=use_generator, pretrained_model=pretrained_weigths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00102cf-04c0-4c8e-9e9f-42a03037f688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
